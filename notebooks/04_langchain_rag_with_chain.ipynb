{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb39f38",
   "metadata": {},
   "source": [
    "# üìì 04 - Pipeline RAG usando LangChain `RetrievalQAChain`\n",
    "\n",
    "Neste notebook, vamos:\n",
    "‚úÖ Usar FAISS como banco vetorial.  \n",
    "‚úÖ Integrar um LLM (OpenAI API) para respostas contextuais.  \n",
    "‚úÖ Usar `RetrievalQAChain` para pipeline de RAG ‚Äúoficial‚Äù do LangChain.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Setup inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34910731",
   "metadata": {},
   "source": [
    "```python\n",
    "# !pip install langchain langchain-community langchain-openai sentence-transformers faiss-cpu\n",
    "# !pip install python-dotenv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c4d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529f3ef4",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Configura√ß√£o de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2bbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef9d8c",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Preparar documentos e chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38319e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ 7 chunks criados.\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de textos/documentos\n",
    "texts = [\n",
    "    \"Retrieval-Augmented Generation (RAG) combina recupera√ß√£o de informa√ß√µes e gera√ß√£o de linguagem natural.\",\n",
    "    \"A IA est√° revolucionando setores como sa√∫de e finan√ßas.\",\n",
    "    \"Python √© uma linguagem de programa√ß√£o muito popular e vers√°til.\"\n",
    "]\n",
    "\n",
    "# Documentos com LangChain\n",
    "docs = [Document(page_content=txt) for txt in texts]\n",
    "\n",
    "# Splitter para criar chunks menores\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "docs_split = splitter.split_documents(docs)\n",
    "\n",
    "print(f\"üîπ {len(docs_split)} chunks criados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc628cd",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Indexar no FAISS via LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f843a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ FAISS indexado com LangChain!\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "vectorstore = FAISS.from_documents(docs_split, embeddings)\n",
    "\n",
    "print(\"üîπ FAISS indexado com LangChain!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494fdec",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Criar RetrievalQAChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef7f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar LLM\n",
    "llm = ChatOpenAI(api_key=openai_api_key, model=\"gpt-3.5-turbo\")  #\"gpt-4o\")\n",
    "\n",
    "# Criar Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # \"stuff\" = coloca tudo no prompt\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192620cf",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Testar o pipeline com qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b282c818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinicius\\AppData\\Local\\Temp\\ipykernel_16448\\2154320861.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Resposta final:\n",
      " A IA est√° revolucionando setores como sa√∫de e linguagem natural.\n",
      "\n",
      "üîπ Documentos recuperados:\n",
      "- A IA est√° revolucionando setores como sa√∫de e\n",
      "- de linguagem natural.\n"
     ]
    }
   ],
   "source": [
    "query = \"Como a IA est√° mudando a ind√∫stria?\"\n",
    "\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"üîπ Resposta final:\\n\", result[\"result\"])\n",
    "print(\"\\nüîπ Documentos recuperados:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"-\", doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edffe7",
   "metadata": {},
   "source": [
    "### Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed1e18",
   "metadata": {},
   "source": [
    "### Adicionando metadados aos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "117d6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Agora cada documento tem metadados\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Retrieval-Augmented Generation (RAG) combina recupera√ß√£o de informa√ß√µes e gera√ß√£o de linguagem natural.\",\n",
    "        metadata={\"source\": \"Blog IA\", \"date\": \"2024-01-10\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A IA est√° revolucionando setores como sa√∫de e finan√ßas.\",\n",
    "        metadata={\"source\": \"Revista Tech\", \"date\": \"2024-03-22\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Python √© uma linguagem de programa√ß√£o muito popular e vers√°til.\",\n",
    "        metadata={\"source\": \"Blog Python\", \"date\": \"2023-11-05\"}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154bb6c7",
   "metadata": {},
   "source": [
    "### Splitter + FAISS com metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25bd6c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ FAISS indexado com LangChain e metadados!\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "docs_split = splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "vectorstore = FAISS.from_documents(docs_split, embeddings)\n",
    "\n",
    "print(\"üîπ FAISS indexado com LangChain e metadados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e19841",
   "metadata": {},
   "source": [
    "### Chain usando RetrievalQAChain com metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32dea398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(api_key=openai_api_key, model=\"gpt-3.5-turbo\")  #\"gpt-4o\")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8122b539",
   "metadata": {},
   "source": [
    "### Consulta e exibi√ß√£o dos metadados dos chunks recuperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb413472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Resposta final:\n",
      " A IA est√° revolucionando setores como sa√∫de e finan√ßas.\n",
      "\n",
      "üîπ Documentos recuperados e metadados:\n",
      "- Fonte: Revista Tech (Data: 2024-03-22)\n",
      "  Texto: A IA est√° revolucionando setores como sa√∫de e\n",
      "- Fonte: Revista Tech (Data: 2024-03-22)\n",
      "  Texto: sa√∫de e finan√ßas.\n"
     ]
    }
   ],
   "source": [
    "query = \"Como a IA est√° mudando as ind√∫strias?\"\n",
    "\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"üîπ Resposta final:\\n\", result[\"result\"])\n",
    "\n",
    "print(\"\\nüîπ Documentos recuperados e metadados:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- Fonte: {doc.metadata['source']} (Data: {doc.metadata['date']})\")\n",
    "    print(\"  Texto:\", doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8035d91",
   "metadata": {},
   "source": [
    "### Testando outros chain_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101a6e4",
   "metadata": {},
   "source": [
    "O LangChain tem v√°rios tipos de Chains que influenciam como o contexto √© formatado:\n",
    "\n",
    "| **chain_type** | **Descri√ß√£o resumida**                                                                                   |\n",
    "|-----------------|----------------------------------------------------------------------------------------------------------|\n",
    "| stuff           | Insere todos os documentos no prompt (padr√£o, r√°pido e simples)                                          |\n",
    "| map_reduce      | Divide em partes menores e combina as respostas (bom para documentos muito grandes)                      |\n",
    "| refine          | Processa o 1¬∫ doc, depois vai ‚Äúrefinando‚Äù com os demais (iterativo, mais preciso)                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09dbc806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Resposta com map_reduce:\n",
      " A IA est√° revolucionando diversas ind√∫strias ao redor do mundo, melhorando a efici√™ncia, a precis√£o, a automa√ß√£o e a personaliza√ß√£o em setores como sa√∫de e financeiro. Na √°rea da sa√∫de, ela est√° possibilitando diagn√≥sticos mais precisos, an√°lise de grandes conjuntos de dados e personaliza√ß√£o de tratamentos. J√° no setor financeiro, a IA est√° sendo usada para detectar fraudes, fazer previs√µes de mercado mais precisas e melhorar a experi√™ncia do cliente. Em resumo, a IA est√° transformando a maneira como as ind√∫strias operam, tornando os processos mais eficientes, inteligentes e adapt√°veis √†s demandas do mercado.\n"
     ]
    }
   ],
   "source": [
    "qa_chain_mapreduce = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "result_mapreduce = qa_chain_mapreduce({\"query\": query})\n",
    "print(\"\\nüîπ Resposta com map_reduce:\\n\", result_mapreduce[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147ef794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Resposta com refine:\n",
      " A intelig√™ncia artificial (IA) est√° revolucionando diversas ind√∫strias de diferentes maneiras. Al√©m dos exemplos anteriores, √© importante destacar o impacto da IA nos setores de sa√∫de e finan√ßas.\n",
      "\n",
      "Na √°rea da sa√∫de, a IA est√° sendo amplamente utilizada para otimizar diagn√≥sticos m√©dicos, personalizar tratamentos com base em dados espec√≠ficos de cada paciente, gerenciar de forma eficiente registros eletr√¥nicos de sa√∫de, prever surtos de doen√ßas e at√© mesmo desenvolver novos medicamentos e terapias.\n",
      "\n",
      "No setor financeiro, a IA tem sido fundamental para prever tend√™ncias de mercado, detectar fraudes em transa√ß√µes financeiras, automatizar processos de an√°lise de risco, criar assistentes virtuais para atendimento ao cliente e at√© mesmo desenvolver algoritmos de negocia√ß√£o de alta frequ√™ncia.\n",
      "\n",
      "Esses avan√ßos tecnol√≥gicos est√£o transformando significativamente as ind√∫strias de sa√∫de e finan√ßas, proporcionando benef√≠cios como maior efici√™ncia, precis√£o nos diagn√≥sticos e tomada de decis√µes, personaliza√ß√£o dos servi√ßos oferecidos e melhorias na experi√™ncia do cliente.\n"
     ]
    }
   ],
   "source": [
    "qa_chain_refine = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "result_refine = qa_chain_refine({\"query\": query})\n",
    "print(\"\\nüîπ Resposta com refine:\\n\", result_refine[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1b38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
